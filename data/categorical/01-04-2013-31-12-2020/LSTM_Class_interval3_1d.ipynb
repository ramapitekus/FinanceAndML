{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7516b82",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7786888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from tensorflow.keras.models import Sequential \n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9401241",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0f0775",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0HH_FAAlRXx"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"1d_indicators.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92b2efe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e30095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7cb3fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bitcoin-fee_to_reward_raw</th>\n",
       "      <th>difficulty-btc--trx3</th>\n",
       "      <th>hashrate-btc--mom3</th>\n",
       "      <th>hashrate-btc--mom7</th>\n",
       "      <th>hashrate-btc--mom30</th>\n",
       "      <th>hashrate-btc--trx3</th>\n",
       "      <th>hashrate-btc--rsi7</th>\n",
       "      <th>hashrate-btc--rsi14</th>\n",
       "      <th>hashrate-btc--roc3</th>\n",
       "      <th>hashrate-btc--roc7</th>\n",
       "      <th>...</th>\n",
       "      <th>top100cap-btc--rsi7</th>\n",
       "      <th>activeaddresses-btc--mom7</th>\n",
       "      <th>activeaddresses-btc--mom14</th>\n",
       "      <th>activeaddresses-btc--trx3</th>\n",
       "      <th>activeaddresses-btc--rsi7</th>\n",
       "      <th>price-btc--trx3</th>\n",
       "      <th>price-btc--rsi3</th>\n",
       "      <th>price-btc--rsi14</th>\n",
       "      <th>price-btc--roc3</th>\n",
       "      <th>1d_binary_price_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.845</td>\n",
       "      <td>6.431394e+12</td>\n",
       "      <td>1.339752e+13</td>\n",
       "      <td>3.328936e+13</td>\n",
       "      <td>3.200</td>\n",
       "      <td>68.982</td>\n",
       "      <td>65.815</td>\n",
       "      <td>10.888</td>\n",
       "      <td>25.713</td>\n",
       "      <td>...</td>\n",
       "      <td>77.854</td>\n",
       "      <td>9581.0</td>\n",
       "      <td>16890.0</td>\n",
       "      <td>-1.376</td>\n",
       "      <td>53.060</td>\n",
       "      <td>3.723</td>\n",
       "      <td>99.456</td>\n",
       "      <td>95.075</td>\n",
       "      <td>9.383</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.338</td>\n",
       "      <td>0.520</td>\n",
       "      <td>3.737455e+12</td>\n",
       "      <td>1.161033e+13</td>\n",
       "      <td>2.889860e+13</td>\n",
       "      <td>3.023</td>\n",
       "      <td>61.645</td>\n",
       "      <td>61.746</td>\n",
       "      <td>6.432</td>\n",
       "      <td>23.112</td>\n",
       "      <td>...</td>\n",
       "      <td>80.298</td>\n",
       "      <td>18862.0</td>\n",
       "      <td>23132.0</td>\n",
       "      <td>1.849</td>\n",
       "      <td>64.122</td>\n",
       "      <td>5.184</td>\n",
       "      <td>99.811</td>\n",
       "      <td>96.416</td>\n",
       "      <td>23.206</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.596</td>\n",
       "      <td>0.314</td>\n",
       "      <td>5.716892e+12</td>\n",
       "      <td>1.457177e+13</td>\n",
       "      <td>2.264479e+13</td>\n",
       "      <td>1.982</td>\n",
       "      <td>58.516</td>\n",
       "      <td>60.024</td>\n",
       "      <td>10.479</td>\n",
       "      <td>31.887</td>\n",
       "      <td>...</td>\n",
       "      <td>74.565</td>\n",
       "      <td>34385.0</td>\n",
       "      <td>44294.0</td>\n",
       "      <td>6.045</td>\n",
       "      <td>71.534</td>\n",
       "      <td>6.968</td>\n",
       "      <td>99.902</td>\n",
       "      <td>97.190</td>\n",
       "      <td>34.759</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.948</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-1.022966e+13</td>\n",
       "      <td>1.791590e+12</td>\n",
       "      <td>2.095298e+13</td>\n",
       "      <td>0.067</td>\n",
       "      <td>49.262</td>\n",
       "      <td>54.803</td>\n",
       "      <td>-15.617</td>\n",
       "      <td>3.350</td>\n",
       "      <td>...</td>\n",
       "      <td>74.737</td>\n",
       "      <td>14427.0</td>\n",
       "      <td>39163.0</td>\n",
       "      <td>7.371</td>\n",
       "      <td>72.299</td>\n",
       "      <td>7.181</td>\n",
       "      <td>99.919</td>\n",
       "      <td>97.368</td>\n",
       "      <td>30.456</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.432</td>\n",
       "      <td>0.689</td>\n",
       "      <td>-1.003014e+13</td>\n",
       "      <td>-7.255264e+12</td>\n",
       "      <td>1.805297e+13</td>\n",
       "      <td>-1.729</td>\n",
       "      <td>43.687</td>\n",
       "      <td>51.468</td>\n",
       "      <td>-16.218</td>\n",
       "      <td>-12.282</td>\n",
       "      <td>...</td>\n",
       "      <td>52.947</td>\n",
       "      <td>16760.0</td>\n",
       "      <td>25062.0</td>\n",
       "      <td>5.263</td>\n",
       "      <td>62.394</td>\n",
       "      <td>6.652</td>\n",
       "      <td>99.941</td>\n",
       "      <td>97.602</td>\n",
       "      <td>19.411</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bitcoin-fee_to_reward_raw  difficulty-btc--trx3  hashrate-btc--mom3  \\\n",
       "0                      0.867                 0.845        6.431394e+12   \n",
       "1                      1.338                 0.520        3.737455e+12   \n",
       "2                      1.596                 0.314        5.716892e+12   \n",
       "3                      1.948                 0.187       -1.022966e+13   \n",
       "4                      1.432                 0.689       -1.003014e+13   \n",
       "\n",
       "   hashrate-btc--mom7  hashrate-btc--mom30  hashrate-btc--trx3  \\\n",
       "0        1.339752e+13         3.328936e+13               3.200   \n",
       "1        1.161033e+13         2.889860e+13               3.023   \n",
       "2        1.457177e+13         2.264479e+13               1.982   \n",
       "3        1.791590e+12         2.095298e+13               0.067   \n",
       "4       -7.255264e+12         1.805297e+13              -1.729   \n",
       "\n",
       "   hashrate-btc--rsi7  hashrate-btc--rsi14  hashrate-btc--roc3  \\\n",
       "0              68.982               65.815              10.888   \n",
       "1              61.645               61.746               6.432   \n",
       "2              58.516               60.024              10.479   \n",
       "3              49.262               54.803             -15.617   \n",
       "4              43.687               51.468             -16.218   \n",
       "\n",
       "   hashrate-btc--roc7  ...  top100cap-btc--rsi7  activeaddresses-btc--mom7  \\\n",
       "0              25.713  ...               77.854                     9581.0   \n",
       "1              23.112  ...               80.298                    18862.0   \n",
       "2              31.887  ...               74.565                    34385.0   \n",
       "3               3.350  ...               74.737                    14427.0   \n",
       "4             -12.282  ...               52.947                    16760.0   \n",
       "\n",
       "   activeaddresses-btc--mom14  activeaddresses-btc--trx3  \\\n",
       "0                     16890.0                     -1.376   \n",
       "1                     23132.0                      1.849   \n",
       "2                     44294.0                      6.045   \n",
       "3                     39163.0                      7.371   \n",
       "4                     25062.0                      5.263   \n",
       "\n",
       "   activeaddresses-btc--rsi7  price-btc--trx3  price-btc--rsi3  \\\n",
       "0                     53.060            3.723           99.456   \n",
       "1                     64.122            5.184           99.811   \n",
       "2                     71.534            6.968           99.902   \n",
       "3                     72.299            7.181           99.919   \n",
       "4                     62.394            6.652           99.941   \n",
       "\n",
       "   price-btc--rsi14  price-btc--roc3  1d_binary_price_change  \n",
       "0            95.075            9.383                     1.0  \n",
       "1            96.416           23.206                     1.0  \n",
       "2            97.190           34.759                     1.0  \n",
       "3            97.368           30.456                     1.0  \n",
       "4            97.602           19.411                     1.0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb27a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2831, 79)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e59bc6",
   "metadata": {},
   "source": [
    "We use iloc to allocate variable X to all features exept the last column which is the dependent variable that is allocated to y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e69ff34",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSzHTpuzmScU"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6dcdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0779d",
   "metadata": {},
   "source": [
    "We perform a 80/20 Train Test split. Shuffling is not ideal since LSTM relies on sequential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc535338",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X,y, test_size=0.2, train_size=0.8, shuffle=False, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8805e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2264, 78)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5412088",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "We create an empty list and append it first with a RobustScaler (removes outliers by removing median and scaling the data according to the quantile range. Default: Interquartile Range), and then with the MinMaxScaler which forces all values to range from 0 to 1 (or -1 to 1 if there are negative values). In pass these scaler transforms in sequence, we use scikit-learn's Pipeline utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b61271",
   "metadata": {},
   "outputs": [],
   "source": [
    "list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "310b2ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list.append(['RobustScaler',RobustScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d4f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list.append(['MinMaxScaler',MinMaxScaler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39b6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=Pipeline(list,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7dca585",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDojXgA7mpWa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 2) Processing RobustScaler, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 2) Processing MinMaxScaler, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "X_train=scale.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fa69b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2264, 78)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a5fb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072708c4",
   "metadata": {},
   "source": [
    "Reshaping needed to fit the required 3-d input in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ad0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd093d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "451374c4",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wNcl2z_JKkM"
   },
   "outputs": [],
   "source": [
    "y_train=y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8456bc2",
   "metadata": {},
   "source": [
    "Convert dependent variable to tpye \"categorical\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd98d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique1, id1 = np.unique(y_train, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef13addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(id1,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5379731b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2264, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3bf8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.reshape(y_train, (y_train.shape[0],1,y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61c4f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea29614",
   "metadata": {
    "colab_type": "text",
    "id": "MVCJxdebqmOr"
   },
   "source": [
    "# **Optimizer and Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ab0b8",
   "metadata": {},
   "source": [
    "First we initiate Keras' LearningRateScheduler which reduces the learning rate and we use (like in the paper) the Adam optimizer with a starting learning rate of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a64e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-3 * 10**(epoch/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1a4760d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868"
   },
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=1e-3,amsgrad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da06d9",
   "metadata": {},
   "source": [
    "We define a sequential model with 300 LSTM units in three hidden layers and a Dense output layer with two units (units determine the dimensionality of the output space. Two, since we have binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d4842ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(300, return_sequences=True, activation='relu', input_shape=(1, X_train.shape[2])))\n",
    "model.add(LSTM(300, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(300, return_sequences=True, activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4116347",
   "metadata": {},
   "source": [
    "ModelCheckpoint saves an intermediate checkpoint if the model is considered \"best\", so the \"best\" model can be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24299c0c",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6"
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/shara/Documents/FinanceAndML-main/data/categorical/01-04-2013-31-12-2020/Best_LSTM_Class_interval3_1d.hdf5'\n",
    "best_model = ModelCheckpoint(path, save_best_only=True, monitor='val_loss', mode='max')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3eb7e95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bIJPsArMr8cs",
    "outputId": "91137564-8bb8-496c-c827-829e240a789a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.6921 - accuracy: 0.5493 - val_loss: 0.6875 - val_accuracy: 0.5551\n",
      "Epoch 2/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6913 - accuracy: 0.5488 - val_loss: 0.6876 - val_accuracy: 0.5551\n",
      "Epoch 3/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6899 - accuracy: 0.5488 - val_loss: 0.6870 - val_accuracy: 0.5551\n",
      "Epoch 4/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6895 - accuracy: 0.5488 - val_loss: 0.6865 - val_accuracy: 0.5551\n",
      "Epoch 5/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6898 - accuracy: 0.5488 - val_loss: 0.6869 - val_accuracy: 0.5551\n",
      "Epoch 6/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6891 - accuracy: 0.5488 - val_loss: 0.6861 - val_accuracy: 0.5551\n",
      "Epoch 7/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6896 - accuracy: 0.5488 - val_loss: 0.6867 - val_accuracy: 0.5551\n",
      "Epoch 8/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6890 - accuracy: 0.5488 - val_loss: 0.6856 - val_accuracy: 0.5551\n",
      "Epoch 9/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6894 - accuracy: 0.5488 - val_loss: 0.6864 - val_accuracy: 0.5551\n",
      "Epoch 10/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6883 - accuracy: 0.5488 - val_loss: 0.6840 - val_accuracy: 0.5551\n",
      "Epoch 11/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6882 - accuracy: 0.5488 - val_loss: 0.6832 - val_accuracy: 0.5551\n",
      "Epoch 12/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6881 - accuracy: 0.5488 - val_loss: 0.6831 - val_accuracy: 0.5551\n",
      "Epoch 13/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6874 - accuracy: 0.5488 - val_loss: 0.6825 - val_accuracy: 0.5551\n",
      "Epoch 14/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6856 - accuracy: 0.5488 - val_loss: 0.6834 - val_accuracy: 0.5551\n",
      "Epoch 15/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6835 - accuracy: 0.5488 - val_loss: 0.6875 - val_accuracy: 0.5551\n",
      "Epoch 16/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6855 - accuracy: 0.5488 - val_loss: 0.6816 - val_accuracy: 0.5551\n",
      "Epoch 17/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6820 - accuracy: 0.5488 - val_loss: 0.6840 - val_accuracy: 0.5551\n",
      "Epoch 18/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6813 - accuracy: 0.5488 - val_loss: 0.6837 - val_accuracy: 0.5551\n",
      "Epoch 19/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6809 - accuracy: 0.5488 - val_loss: 0.6823 - val_accuracy: 0.5551\n",
      "Epoch 20/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6800 - accuracy: 0.5488 - val_loss: 0.6821 - val_accuracy: 0.5551\n",
      "Epoch 21/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6792 - accuracy: 0.5415 - val_loss: 0.6823 - val_accuracy: 0.5639\n",
      "Epoch 22/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6785 - accuracy: 0.5547 - val_loss: 0.6827 - val_accuracy: 0.5903\n",
      "Epoch 23/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6778 - accuracy: 0.5626 - val_loss: 0.6824 - val_accuracy: 0.5815\n",
      "Epoch 24/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6769 - accuracy: 0.5685 - val_loss: 0.6823 - val_accuracy: 0.5947\n",
      "Epoch 25/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6761 - accuracy: 0.5675 - val_loss: 0.6829 - val_accuracy: 0.5683\n",
      "Epoch 26/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6758 - accuracy: 0.5690 - val_loss: 0.6824 - val_accuracy: 0.5815\n",
      "Epoch 27/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6747 - accuracy: 0.5646 - val_loss: 0.6829 - val_accuracy: 0.5727\n",
      "Epoch 28/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6742 - accuracy: 0.5626 - val_loss: 0.6831 - val_accuracy: 0.5683\n",
      "Epoch 29/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6732 - accuracy: 0.5670 - val_loss: 0.6840 - val_accuracy: 0.5463\n",
      "Epoch 30/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6723 - accuracy: 0.5695 - val_loss: 0.6834 - val_accuracy: 0.5639\n",
      "Epoch 31/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6719 - accuracy: 0.5660 - val_loss: 0.6853 - val_accuracy: 0.5639\n",
      "Epoch 32/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6713 - accuracy: 0.5665 - val_loss: 0.6842 - val_accuracy: 0.5639\n",
      "Epoch 33/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6707 - accuracy: 0.5709 - val_loss: 0.6842 - val_accuracy: 0.5683\n",
      "Epoch 34/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6689 - accuracy: 0.5700 - val_loss: 0.6862 - val_accuracy: 0.5595\n",
      "Epoch 35/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6689 - accuracy: 0.5719 - val_loss: 0.6851 - val_accuracy: 0.5771\n",
      "Epoch 36/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6678 - accuracy: 0.5754 - val_loss: 0.6865 - val_accuracy: 0.5727\n",
      "Epoch 37/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6666 - accuracy: 0.5729 - val_loss: 0.6860 - val_accuracy: 0.5859\n",
      "Epoch 38/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6663 - accuracy: 0.5724 - val_loss: 0.7000 - val_accuracy: 0.5595\n",
      "Epoch 39/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6638 - accuracy: 0.5812 - val_loss: 0.6910 - val_accuracy: 0.5463\n",
      "Epoch 40/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6642 - accuracy: 0.5729 - val_loss: 0.6883 - val_accuracy: 0.5859\n",
      "Epoch 41/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6637 - accuracy: 0.5788 - val_loss: 0.6883 - val_accuracy: 0.5463\n",
      "Epoch 42/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6649 - accuracy: 0.5798 - val_loss: 0.6985 - val_accuracy: 0.5595\n",
      "Epoch 43/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6621 - accuracy: 0.5783 - val_loss: 0.6862 - val_accuracy: 0.5815\n",
      "Epoch 44/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6635 - accuracy: 0.5763 - val_loss: 0.6910 - val_accuracy: 0.5903\n",
      "Epoch 45/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6603 - accuracy: 0.5808 - val_loss: 0.6883 - val_accuracy: 0.5947\n",
      "Epoch 46/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6650 - accuracy: 0.5788 - val_loss: 0.6926 - val_accuracy: 0.5639\n",
      "Epoch 47/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6618 - accuracy: 0.5768 - val_loss: 0.6912 - val_accuracy: 0.5639\n",
      "Epoch 48/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6642 - accuracy: 0.5847 - val_loss: 0.6964 - val_accuracy: 0.5639\n",
      "Epoch 49/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6586 - accuracy: 0.5812 - val_loss: 0.6882 - val_accuracy: 0.5815\n",
      "Epoch 50/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6603 - accuracy: 0.5788 - val_loss: 0.6965 - val_accuracy: 0.5683\n",
      "Epoch 51/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6576 - accuracy: 0.5842 - val_loss: 0.6928 - val_accuracy: 0.5771\n",
      "Epoch 52/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6603 - accuracy: 0.5891 - val_loss: 0.7051 - val_accuracy: 0.5727\n",
      "Epoch 53/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6562 - accuracy: 0.5886 - val_loss: 0.6944 - val_accuracy: 0.5727\n",
      "Epoch 54/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6593 - accuracy: 0.5866 - val_loss: 0.7073 - val_accuracy: 0.5551\n",
      "Epoch 55/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6550 - accuracy: 0.5906 - val_loss: 0.6933 - val_accuracy: 0.5859\n",
      "Epoch 56/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6590 - accuracy: 0.5871 - val_loss: 0.7006 - val_accuracy: 0.5771\n",
      "Epoch 57/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6535 - accuracy: 0.5871 - val_loss: 0.6979 - val_accuracy: 0.5727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6616 - accuracy: 0.5866 - val_loss: 0.7027 - val_accuracy: 0.5727\n",
      "Epoch 59/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6530 - accuracy: 0.5920 - val_loss: 0.7021 - val_accuracy: 0.5595\n",
      "Epoch 60/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6634 - accuracy: 0.5852 - val_loss: 0.7095 - val_accuracy: 0.5727\n",
      "Epoch 61/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6573 - accuracy: 0.5788 - val_loss: 0.6973 - val_accuracy: 0.5771\n",
      "Epoch 62/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6579 - accuracy: 0.5906 - val_loss: 0.7061 - val_accuracy: 0.5727\n",
      "Epoch 63/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6525 - accuracy: 0.5901 - val_loss: 0.7053 - val_accuracy: 0.5595\n",
      "Epoch 64/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6534 - accuracy: 0.5866 - val_loss: 0.6945 - val_accuracy: 0.5771\n",
      "Epoch 65/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6533 - accuracy: 0.5950 - val_loss: 0.7455 - val_accuracy: 0.5683\n",
      "Epoch 66/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6544 - accuracy: 0.5847 - val_loss: 0.7008 - val_accuracy: 0.5639\n",
      "Epoch 67/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6523 - accuracy: 0.5950 - val_loss: 0.7180 - val_accuracy: 0.5595\n",
      "Epoch 68/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6484 - accuracy: 0.5920 - val_loss: 0.7028 - val_accuracy: 0.5639\n",
      "Epoch 69/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6498 - accuracy: 0.5896 - val_loss: 0.7284 - val_accuracy: 0.5683\n",
      "Epoch 70/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6518 - accuracy: 0.5862 - val_loss: 0.6948 - val_accuracy: 0.5727\n",
      "Epoch 71/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6497 - accuracy: 0.5994 - val_loss: 0.7209 - val_accuracy: 0.5551\n",
      "Epoch 72/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6506 - accuracy: 0.5876 - val_loss: 0.7161 - val_accuracy: 0.5551\n",
      "Epoch 73/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6448 - accuracy: 0.6004 - val_loss: 0.7221 - val_accuracy: 0.5463\n",
      "Epoch 74/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6635 - accuracy: 0.5749 - val_loss: 0.7098 - val_accuracy: 0.5727\n",
      "Epoch 75/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6549 - accuracy: 0.5886 - val_loss: 0.7127 - val_accuracy: 0.5463\n",
      "Epoch 76/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6725 - accuracy: 0.5773 - val_loss: 0.6965 - val_accuracy: 0.5639\n",
      "Epoch 77/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6529 - accuracy: 0.5881 - val_loss: 0.7129 - val_accuracy: 0.5551\n",
      "Epoch 78/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6492 - accuracy: 0.5871 - val_loss: 0.7386 - val_accuracy: 0.5595\n",
      "Epoch 79/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6457 - accuracy: 0.5925 - val_loss: 0.7277 - val_accuracy: 0.5507\n",
      "Epoch 80/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6551 - accuracy: 0.5920 - val_loss: 0.7686 - val_accuracy: 0.5595\n",
      "Epoch 81/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6439 - accuracy: 0.6092 - val_loss: 0.7502 - val_accuracy: 0.5683\n",
      "Epoch 82/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6513 - accuracy: 0.5871 - val_loss: 0.7844 - val_accuracy: 0.5639\n",
      "Epoch 83/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6416 - accuracy: 0.6058 - val_loss: 0.7585 - val_accuracy: 0.5639\n",
      "Epoch 84/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6502 - accuracy: 0.5984 - val_loss: 0.8453 - val_accuracy: 0.5595\n",
      "Epoch 85/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6396 - accuracy: 0.6078 - val_loss: 0.7510 - val_accuracy: 0.5815\n",
      "Epoch 86/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6389 - accuracy: 0.6087 - val_loss: 0.7498 - val_accuracy: 0.5683\n",
      "Epoch 87/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6677 - accuracy: 0.5523 - val_loss: 0.6864 - val_accuracy: 0.5683\n",
      "Epoch 88/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6630 - accuracy: 0.5832 - val_loss: 0.7223 - val_accuracy: 0.5991\n",
      "Epoch 89/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6473 - accuracy: 0.5911 - val_loss: 0.7269 - val_accuracy: 0.5639\n",
      "Epoch 90/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6505 - accuracy: 0.5866 - val_loss: 0.7806 - val_accuracy: 0.5683\n",
      "Epoch 91/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6378 - accuracy: 0.6004 - val_loss: 0.7269 - val_accuracy: 0.5507\n",
      "Epoch 92/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6472 - accuracy: 0.5970 - val_loss: 0.8123 - val_accuracy: 0.5771\n",
      "Epoch 93/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6374 - accuracy: 0.6078 - val_loss: 0.7068 - val_accuracy: 0.5463\n",
      "Epoch 94/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6598 - accuracy: 0.5871 - val_loss: 0.7423 - val_accuracy: 0.6035\n",
      "Epoch 95/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6396 - accuracy: 0.6004 - val_loss: 0.7389 - val_accuracy: 0.5683\n",
      "Epoch 96/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6370 - accuracy: 0.6028 - val_loss: 0.7967 - val_accuracy: 0.5639\n",
      "Epoch 97/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6340 - accuracy: 0.6078 - val_loss: 0.7535 - val_accuracy: 0.5683\n",
      "Epoch 98/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6315 - accuracy: 0.6171 - val_loss: 0.7591 - val_accuracy: 0.5683\n",
      "Epoch 99/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6306 - accuracy: 0.6171 - val_loss: 0.7509 - val_accuracy: 0.5727\n",
      "Epoch 100/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6302 - accuracy: 0.6171 - val_loss: 0.7518 - val_accuracy: 0.5727\n",
      "Epoch 101/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6304 - accuracy: 0.6053 - val_loss: 0.7291 - val_accuracy: 0.5859\n",
      "Epoch 102/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6308 - accuracy: 0.6024 - val_loss: 0.7741 - val_accuracy: 0.5903\n",
      "Epoch 103/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6272 - accuracy: 0.6107 - val_loss: 0.7580 - val_accuracy: 0.5639\n",
      "Epoch 104/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6296 - accuracy: 0.6073 - val_loss: 0.7485 - val_accuracy: 0.5815\n",
      "Epoch 105/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6251 - accuracy: 0.6102 - val_loss: 0.7564 - val_accuracy: 0.5771\n",
      "Epoch 106/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6569 - accuracy: 0.5734 - val_loss: 0.7146 - val_accuracy: 0.5815\n",
      "Epoch 107/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6432 - accuracy: 0.5955 - val_loss: 0.6927 - val_accuracy: 0.5727\n",
      "Epoch 108/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6476 - accuracy: 0.5935 - val_loss: 0.7052 - val_accuracy: 0.5771\n",
      "Epoch 109/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6536 - accuracy: 0.5891 - val_loss: 0.6953 - val_accuracy: 0.5771\n",
      "Epoch 110/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6319 - accuracy: 0.6014 - val_loss: 0.7479 - val_accuracy: 0.5991\n",
      "Epoch 111/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6335 - accuracy: 0.6068 - val_loss: 0.7236 - val_accuracy: 0.5639\n",
      "Epoch 112/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6303 - accuracy: 0.6141 - val_loss: 0.8589 - val_accuracy: 0.5727\n",
      "Epoch 113/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6524 - accuracy: 0.5920 - val_loss: 0.6996 - val_accuracy: 0.5595\n",
      "Epoch 114/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6369 - accuracy: 0.6068 - val_loss: 0.8580 - val_accuracy: 0.5595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6291 - accuracy: 0.6087 - val_loss: 0.7757 - val_accuracy: 0.5903\n",
      "Epoch 116/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6257 - accuracy: 0.6161 - val_loss: 0.8058 - val_accuracy: 0.5903\n",
      "Epoch 117/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6230 - accuracy: 0.6181 - val_loss: 0.7312 - val_accuracy: 0.5683\n",
      "Epoch 118/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.6230 - accuracy: 0.6161 - val_loss: 0.8758 - val_accuracy: 0.5110\n",
      "Epoch 119/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6165 - accuracy: 0.6269 - val_loss: 0.7951 - val_accuracy: 0.5683\n",
      "Epoch 120/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6173 - accuracy: 0.6166 - val_loss: 0.8073 - val_accuracy: 0.5859\n",
      "Epoch 121/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6136 - accuracy: 0.6220 - val_loss: 0.7608 - val_accuracy: 0.5727\n",
      "Epoch 122/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6172 - accuracy: 0.6181 - val_loss: 0.7368 - val_accuracy: 0.5639\n",
      "Epoch 123/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6150 - accuracy: 0.6298 - val_loss: 0.7693 - val_accuracy: 0.5947\n",
      "Epoch 124/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6122 - accuracy: 0.6190 - val_loss: 0.7669 - val_accuracy: 0.5595\n",
      "Epoch 125/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6147 - accuracy: 0.6195 - val_loss: 0.7560 - val_accuracy: 0.5683\n",
      "Epoch 126/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6135 - accuracy: 0.6166 - val_loss: 0.8155 - val_accuracy: 0.5639\n",
      "Epoch 127/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6133 - accuracy: 0.6289 - val_loss: 0.7924 - val_accuracy: 0.5815\n",
      "Epoch 128/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6182 - accuracy: 0.6240 - val_loss: 0.8374 - val_accuracy: 0.5639\n",
      "Epoch 129/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6172 - accuracy: 0.6303 - val_loss: 0.8892 - val_accuracy: 0.5727\n",
      "Epoch 130/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6230 - accuracy: 0.6136 - val_loss: 0.9175 - val_accuracy: 0.5859\n",
      "Epoch 131/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6432 - accuracy: 0.6087 - val_loss: 0.7300 - val_accuracy: 0.5551\n",
      "Epoch 132/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6342 - accuracy: 0.6087 - val_loss: 0.7165 - val_accuracy: 0.5727\n",
      "Epoch 133/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6510 - accuracy: 0.5911 - val_loss: 0.7085 - val_accuracy: 0.5330\n",
      "Epoch 134/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6507 - accuracy: 0.5955 - val_loss: 0.7025 - val_accuracy: 0.5991\n",
      "Epoch 135/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6255 - accuracy: 0.6205 - val_loss: 0.8747 - val_accuracy: 0.5374\n",
      "Epoch 136/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6434 - accuracy: 0.6141 - val_loss: 0.8712 - val_accuracy: 0.5683\n",
      "Epoch 137/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6230 - accuracy: 0.6176 - val_loss: 0.8851 - val_accuracy: 0.5286\n",
      "Epoch 138/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6122 - accuracy: 0.6249 - val_loss: 0.8786 - val_accuracy: 0.5595\n",
      "Epoch 139/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6066 - accuracy: 0.6298 - val_loss: 0.9395 - val_accuracy: 0.5903\n",
      "Epoch 140/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6107 - accuracy: 0.6176 - val_loss: 0.9247 - val_accuracy: 0.5419\n",
      "Epoch 141/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6041 - accuracy: 0.6225 - val_loss: 0.9657 - val_accuracy: 0.5595\n",
      "Epoch 142/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6048 - accuracy: 0.6220 - val_loss: 0.9062 - val_accuracy: 0.5815\n",
      "Epoch 143/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6097 - accuracy: 0.6186 - val_loss: 0.9959 - val_accuracy: 0.5683\n",
      "Epoch 144/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6162 - accuracy: 0.6186 - val_loss: 0.7125 - val_accuracy: 0.5551\n",
      "Epoch 145/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6170 - accuracy: 0.6269 - val_loss: 0.7973 - val_accuracy: 0.6035\n",
      "Epoch 146/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6022 - accuracy: 0.6279 - val_loss: 0.9164 - val_accuracy: 0.5507\n",
      "Epoch 147/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6009 - accuracy: 0.6348 - val_loss: 0.9587 - val_accuracy: 0.5639\n",
      "Epoch 148/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5945 - accuracy: 0.6402 - val_loss: 0.9380 - val_accuracy: 0.5551\n",
      "Epoch 149/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5959 - accuracy: 0.6362 - val_loss: 0.9656 - val_accuracy: 0.5639\n",
      "Epoch 150/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5938 - accuracy: 0.6372 - val_loss: 0.9111 - val_accuracy: 0.5683\n",
      "Epoch 151/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5992 - accuracy: 0.6308 - val_loss: 0.9194 - val_accuracy: 0.5771\n",
      "Epoch 152/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6009 - accuracy: 0.6328 - val_loss: 0.8522 - val_accuracy: 0.5374\n",
      "Epoch 153/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6163 - accuracy: 0.6205 - val_loss: 0.8695 - val_accuracy: 0.5991\n",
      "Epoch 154/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5923 - accuracy: 0.6343 - val_loss: 0.8730 - val_accuracy: 0.5903\n",
      "Epoch 155/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5883 - accuracy: 0.6431 - val_loss: 0.8640 - val_accuracy: 0.5903\n",
      "Epoch 156/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5858 - accuracy: 0.6333 - val_loss: 0.8924 - val_accuracy: 0.5683\n",
      "Epoch 157/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5919 - accuracy: 0.6348 - val_loss: 0.8979 - val_accuracy: 0.5727\n",
      "Epoch 158/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5835 - accuracy: 0.6490 - val_loss: 0.9121 - val_accuracy: 0.5639\n",
      "Epoch 159/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5819 - accuracy: 0.6377 - val_loss: 0.8505 - val_accuracy: 0.5507\n",
      "Epoch 160/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5847 - accuracy: 0.6372 - val_loss: 0.9516 - val_accuracy: 0.5463\n",
      "Epoch 161/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5813 - accuracy: 0.6426 - val_loss: 0.8315 - val_accuracy: 0.5374\n",
      "Epoch 162/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5937 - accuracy: 0.6323 - val_loss: 0.9012 - val_accuracy: 0.5595\n",
      "Epoch 163/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5854 - accuracy: 0.6298 - val_loss: 0.7931 - val_accuracy: 0.5463\n",
      "Epoch 164/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5830 - accuracy: 0.6421 - val_loss: 0.7998 - val_accuracy: 0.5683\n",
      "Epoch 165/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5768 - accuracy: 0.6460 - val_loss: 0.8510 - val_accuracy: 0.5595\n",
      "Epoch 166/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5800 - accuracy: 0.6465 - val_loss: 0.8530 - val_accuracy: 0.5507\n",
      "Epoch 167/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6117 - accuracy: 0.6294 - val_loss: 0.7132 - val_accuracy: 0.5551\n",
      "Epoch 168/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6194 - accuracy: 0.6254 - val_loss: 0.7091 - val_accuracy: 0.5859\n",
      "Epoch 169/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6140 - accuracy: 0.6146 - val_loss: 0.7063 - val_accuracy: 0.5463\n",
      "Epoch 170/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6118 - accuracy: 0.6117 - val_loss: 0.7530 - val_accuracy: 0.5859\n",
      "Epoch 171/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6020 - accuracy: 0.6460 - val_loss: 0.8838 - val_accuracy: 0.5727\n",
      "Epoch 172/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5875 - accuracy: 0.6421 - val_loss: 0.7794 - val_accuracy: 0.5815\n",
      "Epoch 173/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5861 - accuracy: 0.6431 - val_loss: 0.9918 - val_accuracy: 0.5727\n",
      "Epoch 174/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5750 - accuracy: 0.6568 - val_loss: 0.8658 - val_accuracy: 0.5771\n",
      "Epoch 175/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5650 - accuracy: 0.6544 - val_loss: 0.9012 - val_accuracy: 0.5595\n",
      "Epoch 176/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5649 - accuracy: 0.6588 - val_loss: 0.8687 - val_accuracy: 0.5595\n",
      "Epoch 177/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5581 - accuracy: 0.6662 - val_loss: 0.9245 - val_accuracy: 0.5595\n",
      "Epoch 178/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5587 - accuracy: 0.6637 - val_loss: 0.7977 - val_accuracy: 0.5771\n",
      "Epoch 179/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5592 - accuracy: 0.6632 - val_loss: 0.8040 - val_accuracy: 0.5419\n",
      "Epoch 180/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5514 - accuracy: 0.6696 - val_loss: 0.7997 - val_accuracy: 0.5463\n",
      "Epoch 181/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5598 - accuracy: 0.6711 - val_loss: 0.8944 - val_accuracy: 0.5683\n",
      "Epoch 182/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5550 - accuracy: 0.6681 - val_loss: 1.0664 - val_accuracy: 0.5374\n",
      "Epoch 183/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5528 - accuracy: 0.6726 - val_loss: 1.0512 - val_accuracy: 0.5639\n",
      "Epoch 184/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5610 - accuracy: 0.6706 - val_loss: 0.9346 - val_accuracy: 0.5595\n",
      "Epoch 185/5000\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.5643 - accuracy: 0.6676 - val_loss: 1.0855 - val_accuracy: 0.5286\n",
      "Epoch 186/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5535 - accuracy: 0.6701 - val_loss: 1.0465 - val_accuracy: 0.5639\n",
      "Epoch 187/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5960 - accuracy: 0.6475 - val_loss: 1.1822 - val_accuracy: 0.5727\n",
      "Epoch 188/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6007 - accuracy: 0.6284 - val_loss: 0.8876 - val_accuracy: 0.5507\n",
      "Epoch 189/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6337 - accuracy: 0.5950 - val_loss: 0.8393 - val_accuracy: 0.4802\n",
      "Epoch 190/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6094 - accuracy: 0.6303 - val_loss: 0.9401 - val_accuracy: 0.5286\n",
      "Epoch 191/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5899 - accuracy: 0.6421 - val_loss: 1.0077 - val_accuracy: 0.5639\n",
      "Epoch 192/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5666 - accuracy: 0.6608 - val_loss: 1.1127 - val_accuracy: 0.5551\n",
      "Epoch 193/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5578 - accuracy: 0.6583 - val_loss: 1.0594 - val_accuracy: 0.5551\n",
      "Epoch 194/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5550 - accuracy: 0.6657 - val_loss: 1.1699 - val_accuracy: 0.5859\n",
      "Epoch 195/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5552 - accuracy: 0.6706 - val_loss: 1.0931 - val_accuracy: 0.5727\n",
      "Epoch 196/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5490 - accuracy: 0.6794 - val_loss: 1.1774 - val_accuracy: 0.5683\n",
      "Epoch 197/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5447 - accuracy: 0.6780 - val_loss: 1.1940 - val_accuracy: 0.5551\n",
      "Epoch 198/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5443 - accuracy: 0.6789 - val_loss: 1.1735 - val_accuracy: 0.5815\n",
      "Epoch 199/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5449 - accuracy: 0.6780 - val_loss: 1.1321 - val_accuracy: 0.5771\n",
      "Epoch 200/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5558 - accuracy: 0.6726 - val_loss: 1.1351 - val_accuracy: 0.5771\n",
      "Epoch 201/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5604 - accuracy: 0.6554 - val_loss: 0.9635 - val_accuracy: 0.5463\n",
      "Epoch 202/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5561 - accuracy: 0.6706 - val_loss: 1.0791 - val_accuracy: 0.5374\n",
      "Epoch 203/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5513 - accuracy: 0.6730 - val_loss: 1.1539 - val_accuracy: 0.5198\n",
      "Epoch 204/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5383 - accuracy: 0.6829 - val_loss: 1.2391 - val_accuracy: 0.5110\n",
      "Epoch 205/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5386 - accuracy: 0.6834 - val_loss: 1.2109 - val_accuracy: 0.5198\n",
      "Epoch 206/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5359 - accuracy: 0.6858 - val_loss: 1.1987 - val_accuracy: 0.5198\n",
      "Epoch 207/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5352 - accuracy: 0.6878 - val_loss: 1.2174 - val_accuracy: 0.5463\n",
      "Epoch 208/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5345 - accuracy: 0.6848 - val_loss: 1.2149 - val_accuracy: 0.5066\n",
      "Epoch 209/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5286 - accuracy: 0.6927 - val_loss: 1.2138 - val_accuracy: 0.5330\n",
      "Epoch 210/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5376 - accuracy: 0.6843 - val_loss: 0.9347 - val_accuracy: 0.5110\n",
      "Epoch 211/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6243 - accuracy: 0.6573 - val_loss: 0.8259 - val_accuracy: 0.5771\n",
      "Epoch 212/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.6061 - accuracy: 0.6352 - val_loss: 0.9867 - val_accuracy: 0.5507\n",
      "Epoch 213/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5608 - accuracy: 0.6892 - val_loss: 0.9554 - val_accuracy: 0.5551\n",
      "Epoch 214/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5375 - accuracy: 0.6829 - val_loss: 1.0096 - val_accuracy: 0.5374\n",
      "Epoch 215/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5240 - accuracy: 0.6946 - val_loss: 1.1911 - val_accuracy: 0.5463\n",
      "Epoch 216/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5238 - accuracy: 0.6922 - val_loss: 1.1660 - val_accuracy: 0.5110\n",
      "Epoch 217/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5093 - accuracy: 0.7035 - val_loss: 1.2637 - val_accuracy: 0.5066\n",
      "Epoch 218/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5099 - accuracy: 0.7010 - val_loss: 1.3066 - val_accuracy: 0.5066\n",
      "Epoch 219/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.5059 - accuracy: 0.7079 - val_loss: 1.2855 - val_accuracy: 0.4934\n",
      "Epoch 220/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.5020 - accuracy: 0.7104 - val_loss: 1.3779 - val_accuracy: 0.5066\n",
      "Epoch 221/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.5038 - accuracy: 0.7104 - val_loss: 1.4127 - val_accuracy: 0.5022\n",
      "Epoch 222/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4964 - accuracy: 0.7167 - val_loss: 1.4530 - val_accuracy: 0.5066\n",
      "Epoch 223/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5041 - accuracy: 0.7148 - val_loss: 1.3716 - val_accuracy: 0.5242\n",
      "Epoch 224/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5106 - accuracy: 0.7187 - val_loss: 1.4309 - val_accuracy: 0.5463\n",
      "Epoch 225/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5092 - accuracy: 0.7113 - val_loss: 1.1511 - val_accuracy: 0.5374\n",
      "Epoch 226/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5013 - accuracy: 0.7123 - val_loss: 1.1963 - val_accuracy: 0.4934\n",
      "Epoch 227/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5328 - accuracy: 0.6986 - val_loss: 1.0281 - val_accuracy: 0.4802\n",
      "Epoch 228/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6017 - accuracy: 0.6622 - val_loss: 0.8071 - val_accuracy: 0.5595\n",
      "Epoch 229/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6205 - accuracy: 0.6436 - val_loss: 0.9011 - val_accuracy: 0.5727\n",
      "Epoch 230/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5600 - accuracy: 0.6892 - val_loss: 1.0874 - val_accuracy: 0.5551\n",
      "Epoch 231/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5448 - accuracy: 0.6932 - val_loss: 1.2611 - val_accuracy: 0.5286\n",
      "Epoch 232/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5206 - accuracy: 0.7113 - val_loss: 1.0859 - val_accuracy: 0.4978\n",
      "Epoch 233/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5188 - accuracy: 0.7059 - val_loss: 0.9229 - val_accuracy: 0.5330\n",
      "Epoch 234/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4988 - accuracy: 0.7153 - val_loss: 1.1930 - val_accuracy: 0.5242\n",
      "Epoch 235/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4851 - accuracy: 0.7270 - val_loss: 1.2074 - val_accuracy: 0.5110\n",
      "Epoch 236/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4867 - accuracy: 0.7241 - val_loss: 1.2580 - val_accuracy: 0.5022\n",
      "Epoch 237/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4776 - accuracy: 0.7413 - val_loss: 1.2721 - val_accuracy: 0.5374\n",
      "Epoch 238/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4743 - accuracy: 0.7374 - val_loss: 1.2714 - val_accuracy: 0.5154\n",
      "Epoch 239/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4693 - accuracy: 0.7457 - val_loss: 1.2132 - val_accuracy: 0.5242\n",
      "Epoch 240/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4666 - accuracy: 0.7447 - val_loss: 1.3228 - val_accuracy: 0.5066\n",
      "Epoch 241/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4667 - accuracy: 0.7383 - val_loss: 1.2409 - val_accuracy: 0.5154\n",
      "Epoch 242/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4695 - accuracy: 0.7423 - val_loss: 1.1729 - val_accuracy: 0.5330\n",
      "Epoch 243/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4637 - accuracy: 0.7506 - val_loss: 1.3413 - val_accuracy: 0.5066\n",
      "Epoch 244/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5142 - accuracy: 0.7079 - val_loss: 0.9915 - val_accuracy: 0.5595\n",
      "Epoch 245/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5529 - accuracy: 0.6917 - val_loss: 1.2228 - val_accuracy: 0.5507\n",
      "Epoch 246/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5470 - accuracy: 0.7113 - val_loss: 1.1578 - val_accuracy: 0.5110\n",
      "Epoch 247/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5156 - accuracy: 0.7221 - val_loss: 1.0268 - val_accuracy: 0.5110\n",
      "Epoch 248/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5189 - accuracy: 0.7187 - val_loss: 1.1467 - val_accuracy: 0.5419\n",
      "Epoch 249/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5357 - accuracy: 0.6917 - val_loss: 0.8207 - val_accuracy: 0.5683\n",
      "Epoch 250/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5065 - accuracy: 0.7285 - val_loss: 0.9749 - val_accuracy: 0.5419\n",
      "Epoch 251/5000\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.73 - 1s 12ms/step - loss: 0.4828 - accuracy: 0.7344 - val_loss: 1.1116 - val_accuracy: 0.4934\n",
      "Epoch 252/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4626 - accuracy: 0.7506 - val_loss: 1.2155 - val_accuracy: 0.4934\n",
      "Epoch 253/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4650 - accuracy: 0.7452 - val_loss: 1.2488 - val_accuracy: 0.5066\n",
      "Epoch 254/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4626 - accuracy: 0.7496 - val_loss: 1.2585 - val_accuracy: 0.4978\n",
      "Epoch 255/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4659 - accuracy: 0.7447 - val_loss: 1.2656 - val_accuracy: 0.4934\n",
      "Epoch 256/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.4550 - accuracy: 0.7595 - val_loss: 1.3245 - val_accuracy: 0.4890\n",
      "Epoch 257/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4489 - accuracy: 0.7604 - val_loss: 1.2631 - val_accuracy: 0.5066\n",
      "Epoch 258/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4576 - accuracy: 0.7541 - val_loss: 1.3251 - val_accuracy: 0.5110\n",
      "Epoch 259/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4435 - accuracy: 0.7727 - val_loss: 1.3515 - val_accuracy: 0.4758\n",
      "Epoch 260/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4457 - accuracy: 0.7604 - val_loss: 1.3340 - val_accuracy: 0.4626\n",
      "Epoch 261/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4480 - accuracy: 0.7545 - val_loss: 1.2241 - val_accuracy: 0.4626\n",
      "Epoch 262/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4515 - accuracy: 0.7521 - val_loss: 1.3424 - val_accuracy: 0.4714\n",
      "Epoch 263/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4546 - accuracy: 0.7482 - val_loss: 1.3820 - val_accuracy: 0.5022\n",
      "Epoch 264/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4481 - accuracy: 0.7580 - val_loss: 1.4105 - val_accuracy: 0.4934\n",
      "Epoch 265/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4525 - accuracy: 0.7595 - val_loss: 1.4975 - val_accuracy: 0.5110\n",
      "Epoch 266/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4549 - accuracy: 0.7644 - val_loss: 1.5135 - val_accuracy: 0.5066\n",
      "Epoch 267/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4551 - accuracy: 0.7570 - val_loss: 1.4994 - val_accuracy: 0.4846\n",
      "Epoch 268/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4508 - accuracy: 0.7585 - val_loss: 1.5212 - val_accuracy: 0.4978\n",
      "Epoch 269/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5128 - accuracy: 0.7138 - val_loss: 1.2133 - val_accuracy: 0.5110\n",
      "Epoch 270/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6598 - accuracy: 0.6377 - val_loss: 0.8666 - val_accuracy: 0.5198\n",
      "Epoch 271/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6026 - accuracy: 0.6554 - val_loss: 0.7986 - val_accuracy: 0.5815\n",
      "Epoch 272/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5463 - accuracy: 0.6897 - val_loss: 0.8369 - val_accuracy: 0.5507\n",
      "Epoch 273/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5254 - accuracy: 0.7050 - val_loss: 1.0113 - val_accuracy: 0.5330\n",
      "Epoch 274/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5068 - accuracy: 0.7143 - val_loss: 1.0642 - val_accuracy: 0.5330\n",
      "Epoch 275/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4962 - accuracy: 0.7113 - val_loss: 1.0890 - val_accuracy: 0.5242\n",
      "Epoch 276/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4695 - accuracy: 0.7447 - val_loss: 1.2913 - val_accuracy: 0.5463\n",
      "Epoch 277/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4345 - accuracy: 0.7688 - val_loss: 1.4571 - val_accuracy: 0.5507\n",
      "Epoch 278/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4323 - accuracy: 0.7673 - val_loss: 1.5516 - val_accuracy: 0.5463\n",
      "Epoch 279/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4234 - accuracy: 0.7698 - val_loss: 1.4898 - val_accuracy: 0.5507\n",
      "Epoch 280/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4260 - accuracy: 0.7683 - val_loss: 1.5668 - val_accuracy: 0.5330\n",
      "Epoch 281/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4163 - accuracy: 0.7766 - val_loss: 1.5829 - val_accuracy: 0.5198\n",
      "Epoch 282/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4121 - accuracy: 0.7776 - val_loss: 1.5892 - val_accuracy: 0.5286\n",
      "Epoch 283/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4089 - accuracy: 0.7806 - val_loss: 1.6055 - val_accuracy: 0.5242\n",
      "Epoch 284/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4053 - accuracy: 0.7889 - val_loss: 1.6473 - val_accuracy: 0.5066\n",
      "Epoch 285/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.4022 - accuracy: 0.7820 - val_loss: 1.6582 - val_accuracy: 0.5022\n",
      "Epoch 286/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.4006 - accuracy: 0.7835 - val_loss: 1.6378 - val_accuracy: 0.5066\n",
      "Epoch 287/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4010 - accuracy: 0.7884 - val_loss: 1.6470 - val_accuracy: 0.5022\n",
      "Epoch 288/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4724 - accuracy: 0.7521 - val_loss: 1.1985 - val_accuracy: 0.4978\n",
      "Epoch 289/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6570 - accuracy: 0.6794 - val_loss: 1.1467 - val_accuracy: 0.5507\n",
      "Epoch 290/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6086 - accuracy: 0.6657 - val_loss: 0.8512 - val_accuracy: 0.5374\n",
      "Epoch 291/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5168 - accuracy: 0.7148 - val_loss: 0.9233 - val_accuracy: 0.5463\n",
      "Epoch 292/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4826 - accuracy: 0.7344 - val_loss: 0.9851 - val_accuracy: 0.5419\n",
      "Epoch 293/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4599 - accuracy: 0.7496 - val_loss: 1.0599 - val_accuracy: 0.5463\n",
      "Epoch 294/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4515 - accuracy: 0.7526 - val_loss: 1.2128 - val_accuracy: 0.5374\n",
      "Epoch 295/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4273 - accuracy: 0.7673 - val_loss: 1.5092 - val_accuracy: 0.5198\n",
      "Epoch 296/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4098 - accuracy: 0.7796 - val_loss: 1.6511 - val_accuracy: 0.5066\n",
      "Epoch 297/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4332 - accuracy: 0.7722 - val_loss: 1.5757 - val_accuracy: 0.5022\n",
      "Epoch 298/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4152 - accuracy: 0.7801 - val_loss: 1.5352 - val_accuracy: 0.5154\n",
      "Epoch 299/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3881 - accuracy: 0.8027 - val_loss: 1.7028 - val_accuracy: 0.5110\n",
      "Epoch 300/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3891 - accuracy: 0.8115 - val_loss: 1.7393 - val_accuracy: 0.5110\n",
      "Epoch 301/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3838 - accuracy: 0.8110 - val_loss: 1.7956 - val_accuracy: 0.4978\n",
      "Epoch 302/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.4015 - accuracy: 0.7933 - val_loss: 1.6627 - val_accuracy: 0.5022\n",
      "Epoch 303/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3789 - accuracy: 0.8105 - val_loss: 1.8327 - val_accuracy: 0.5198\n",
      "Epoch 304/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3844 - accuracy: 0.8017 - val_loss: 1.8696 - val_accuracy: 0.5066\n",
      "Epoch 305/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3655 - accuracy: 0.8149 - val_loss: 1.9305 - val_accuracy: 0.5154\n",
      "Epoch 306/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3765 - accuracy: 0.8115 - val_loss: 1.8924 - val_accuracy: 0.5242\n",
      "Epoch 307/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3547 - accuracy: 0.8297 - val_loss: 1.9436 - val_accuracy: 0.5463\n",
      "Epoch 308/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.3736 - accuracy: 0.8213 - val_loss: 1.9293 - val_accuracy: 0.5463\n",
      "Epoch 309/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3605 - accuracy: 0.8203 - val_loss: 1.9435 - val_accuracy: 0.5198\n",
      "Epoch 310/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3688 - accuracy: 0.8218 - val_loss: 2.0117 - val_accuracy: 0.5066\n",
      "Epoch 311/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3577 - accuracy: 0.8252 - val_loss: 2.0303 - val_accuracy: 0.5286\n",
      "Epoch 312/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3471 - accuracy: 0.8292 - val_loss: 2.0958 - val_accuracy: 0.5330\n",
      "Epoch 313/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3554 - accuracy: 0.8247 - val_loss: 2.0945 - val_accuracy: 0.5463\n",
      "Epoch 314/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3824 - accuracy: 0.8022 - val_loss: 2.0110 - val_accuracy: 0.5374\n",
      "Epoch 315/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3917 - accuracy: 0.8017 - val_loss: 1.9504 - val_accuracy: 0.5463\n",
      "Epoch 316/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4465 - accuracy: 0.7688 - val_loss: 1.6316 - val_accuracy: 0.4802\n",
      "Epoch 317/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6041 - accuracy: 0.6848 - val_loss: 1.7001 - val_accuracy: 0.4493\n",
      "Epoch 318/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.6141 - accuracy: 0.6740 - val_loss: 1.2938 - val_accuracy: 0.4890\n",
      "Epoch 319/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5516 - accuracy: 0.6824 - val_loss: 1.7333 - val_accuracy: 0.5066\n",
      "Epoch 320/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.5021 - accuracy: 0.7447 - val_loss: 1.2919 - val_accuracy: 0.5286\n",
      "Epoch 321/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4451 - accuracy: 0.7521 - val_loss: 1.4153 - val_accuracy: 0.5066\n",
      "Epoch 322/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4091 - accuracy: 0.7815 - val_loss: 1.8084 - val_accuracy: 0.5330\n",
      "Epoch 323/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4004 - accuracy: 0.7899 - val_loss: 1.8766 - val_accuracy: 0.4758\n",
      "Epoch 324/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3647 - accuracy: 0.8144 - val_loss: 1.8469 - val_accuracy: 0.5110\n",
      "Epoch 325/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3560 - accuracy: 0.8243 - val_loss: 1.9298 - val_accuracy: 0.5242\n",
      "Epoch 326/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3495 - accuracy: 0.8292 - val_loss: 1.9383 - val_accuracy: 0.5286\n",
      "Epoch 327/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3449 - accuracy: 0.8233 - val_loss: 1.9797 - val_accuracy: 0.5198\n",
      "Epoch 328/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3459 - accuracy: 0.8218 - val_loss: 1.9609 - val_accuracy: 0.5242\n",
      "Epoch 329/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3413 - accuracy: 0.8311 - val_loss: 1.9649 - val_accuracy: 0.5110\n",
      "Epoch 330/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.3372 - accuracy: 0.8301 - val_loss: 1.9886 - val_accuracy: 0.5110\n",
      "Epoch 331/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3310 - accuracy: 0.8336 - val_loss: 2.0771 - val_accuracy: 0.5066\n",
      "Epoch 332/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3282 - accuracy: 0.8346 - val_loss: 2.1239 - val_accuracy: 0.5066\n",
      "Epoch 333/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.3231 - accuracy: 0.8375 - val_loss: 2.1183 - val_accuracy: 0.5198\n",
      "Epoch 334/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3208 - accuracy: 0.8454 - val_loss: 2.1222 - val_accuracy: 0.5198\n",
      "Epoch 335/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3175 - accuracy: 0.8459 - val_loss: 2.1736 - val_accuracy: 0.5286\n",
      "Epoch 336/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3137 - accuracy: 0.8473 - val_loss: 2.2376 - val_accuracy: 0.5330\n",
      "Epoch 337/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3144 - accuracy: 0.8468 - val_loss: 2.2533 - val_accuracy: 0.5374\n",
      "Epoch 338/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3123 - accuracy: 0.8463 - val_loss: 2.2847 - val_accuracy: 0.5242\n",
      "Epoch 339/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3119 - accuracy: 0.8478 - val_loss: 2.2629 - val_accuracy: 0.5154\n",
      "Epoch 340/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3171 - accuracy: 0.8439 - val_loss: 2.1743 - val_accuracy: 0.5110\n",
      "Epoch 341/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3110 - accuracy: 0.8498 - val_loss: 2.2926 - val_accuracy: 0.5066\n",
      "Epoch 342/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3091 - accuracy: 0.8488 - val_loss: 2.2256 - val_accuracy: 0.5154\n",
      "Epoch 343/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3157 - accuracy: 0.8429 - val_loss: 2.2610 - val_accuracy: 0.5286\n",
      "Epoch 344/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3025 - accuracy: 0.8552 - val_loss: 2.3262 - val_accuracy: 0.5022\n",
      "Epoch 345/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3239 - accuracy: 0.8439 - val_loss: 2.0950 - val_accuracy: 0.4890\n",
      "Epoch 346/5000\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.84 - 1s 12ms/step - loss: 0.3133 - accuracy: 0.8419 - val_loss: 2.4224 - val_accuracy: 0.4978\n",
      "Epoch 347/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2986 - accuracy: 0.8527 - val_loss: 2.3949 - val_accuracy: 0.5066\n",
      "Epoch 348/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2935 - accuracy: 0.8547 - val_loss: 2.3635 - val_accuracy: 0.4846\n",
      "Epoch 349/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3033 - accuracy: 0.8454 - val_loss: 2.4853 - val_accuracy: 0.5022\n",
      "Epoch 350/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3337 - accuracy: 0.8321 - val_loss: 2.3705 - val_accuracy: 0.5286\n",
      "Epoch 351/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3280 - accuracy: 0.8449 - val_loss: 2.1995 - val_accuracy: 0.5198\n",
      "Epoch 352/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3466 - accuracy: 0.8233 - val_loss: 2.0403 - val_accuracy: 0.4978\n",
      "Epoch 353/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3491 - accuracy: 0.8247 - val_loss: 2.3155 - val_accuracy: 0.4978\n",
      "Epoch 354/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3249 - accuracy: 0.8517 - val_loss: 2.3514 - val_accuracy: 0.4802\n",
      "Epoch 355/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3899 - accuracy: 0.8090 - val_loss: 1.9553 - val_accuracy: 0.4934\n",
      "Epoch 356/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3633 - accuracy: 0.8380 - val_loss: 2.1330 - val_accuracy: 0.5022\n",
      "Epoch 357/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3236 - accuracy: 0.8468 - val_loss: 2.2851 - val_accuracy: 0.5066\n",
      "Epoch 358/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2915 - accuracy: 0.8601 - val_loss: 2.2353 - val_accuracy: 0.5154\n",
      "Epoch 359/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2755 - accuracy: 0.8704 - val_loss: 2.1779 - val_accuracy: 0.5198\n",
      "Epoch 360/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2701 - accuracy: 0.8748 - val_loss: 2.1983 - val_accuracy: 0.5419\n",
      "Epoch 361/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2597 - accuracy: 0.8758 - val_loss: 2.2593 - val_accuracy: 0.5242\n",
      "Epoch 362/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2556 - accuracy: 0.8787 - val_loss: 2.2822 - val_accuracy: 0.5419\n",
      "Epoch 363/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2500 - accuracy: 0.8807 - val_loss: 2.3716 - val_accuracy: 0.5198\n",
      "Epoch 364/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2506 - accuracy: 0.8822 - val_loss: 2.3771 - val_accuracy: 0.5374\n",
      "Epoch 365/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2513 - accuracy: 0.8817 - val_loss: 2.4172 - val_accuracy: 0.5286\n",
      "Epoch 366/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2472 - accuracy: 0.8812 - val_loss: 2.4389 - val_accuracy: 0.5419\n",
      "Epoch 367/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2482 - accuracy: 0.8837 - val_loss: 2.4264 - val_accuracy: 0.5242\n",
      "Epoch 368/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2464 - accuracy: 0.8792 - val_loss: 2.5135 - val_accuracy: 0.5286\n",
      "Epoch 369/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2468 - accuracy: 0.8827 - val_loss: 2.5393 - val_accuracy: 0.5198\n",
      "Epoch 370/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2473 - accuracy: 0.8812 - val_loss: 2.4746 - val_accuracy: 0.5419\n",
      "Epoch 371/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2776 - accuracy: 0.8743 - val_loss: 2.3912 - val_accuracy: 0.5551\n",
      "Epoch 372/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3710 - accuracy: 0.8238 - val_loss: 1.9899 - val_accuracy: 0.5286\n",
      "Epoch 373/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3503 - accuracy: 0.8341 - val_loss: 2.0672 - val_accuracy: 0.5595\n",
      "Epoch 374/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3245 - accuracy: 0.8346 - val_loss: 2.1306 - val_accuracy: 0.5330\n",
      "Epoch 375/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3404 - accuracy: 0.8434 - val_loss: 2.2401 - val_accuracy: 0.5022\n",
      "Epoch 376/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3408 - accuracy: 0.8326 - val_loss: 2.0031 - val_accuracy: 0.5286\n",
      "Epoch 377/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2977 - accuracy: 0.8562 - val_loss: 2.3879 - val_accuracy: 0.5639\n",
      "Epoch 378/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3179 - accuracy: 0.8488 - val_loss: 2.3697 - val_accuracy: 0.5286\n",
      "Epoch 379/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2609 - accuracy: 0.8817 - val_loss: 2.4413 - val_accuracy: 0.5286\n",
      "Epoch 380/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2443 - accuracy: 0.8886 - val_loss: 2.5134 - val_accuracy: 0.5507\n",
      "Epoch 381/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2383 - accuracy: 0.8935 - val_loss: 2.4884 - val_accuracy: 0.5066\n",
      "Epoch 382/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2295 - accuracy: 0.8969 - val_loss: 2.5386 - val_accuracy: 0.5286\n",
      "Epoch 383/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2311 - accuracy: 0.8989 - val_loss: 2.5646 - val_accuracy: 0.5330\n",
      "Epoch 384/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2237 - accuracy: 0.9003 - val_loss: 2.5691 - val_accuracy: 0.5507\n",
      "Epoch 385/5000\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.90 - 1s 12ms/step - loss: 0.2194 - accuracy: 0.9062 - val_loss: 2.5647 - val_accuracy: 0.5286\n",
      "Epoch 386/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2202 - accuracy: 0.9062 - val_loss: 2.6795 - val_accuracy: 0.5154\n",
      "Epoch 387/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2163 - accuracy: 0.9048 - val_loss: 2.6810 - val_accuracy: 0.5110\n",
      "Epoch 388/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2185 - accuracy: 0.9018 - val_loss: 2.7178 - val_accuracy: 0.5022\n",
      "Epoch 389/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2135 - accuracy: 0.9062 - val_loss: 2.7037 - val_accuracy: 0.5154\n",
      "Epoch 390/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2207 - accuracy: 0.9033 - val_loss: 2.8433 - val_accuracy: 0.4978\n",
      "Epoch 391/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2182 - accuracy: 0.9018 - val_loss: 2.7830 - val_accuracy: 0.4934\n",
      "Epoch 392/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2697 - accuracy: 0.8871 - val_loss: 2.2391 - val_accuracy: 0.5374\n",
      "Epoch 393/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2639 - accuracy: 0.8812 - val_loss: 2.5355 - val_accuracy: 0.5419\n",
      "Epoch 394/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2822 - accuracy: 0.8665 - val_loss: 2.6134 - val_accuracy: 0.5242\n",
      "Epoch 395/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2665 - accuracy: 0.8837 - val_loss: 2.3498 - val_accuracy: 0.5110\n",
      "Epoch 396/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2924 - accuracy: 0.8616 - val_loss: 2.4221 - val_accuracy: 0.5242\n",
      "Epoch 397/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2383 - accuracy: 0.8920 - val_loss: 2.4839 - val_accuracy: 0.5286\n",
      "Epoch 398/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.2235 - accuracy: 0.8945 - val_loss: 2.5958 - val_accuracy: 0.4978\n",
      "Epoch 399/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2304 - accuracy: 0.8959 - val_loss: 2.5504 - val_accuracy: 0.5022\n",
      "Epoch 400/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2364 - accuracy: 0.8881 - val_loss: 2.5282 - val_accuracy: 0.5198\n",
      "Epoch 401/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.2077 - accuracy: 0.9102 - val_loss: 2.5297 - val_accuracy: 0.5022\n",
      "Epoch 402/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2098 - accuracy: 0.9077 - val_loss: 2.5686 - val_accuracy: 0.5066\n",
      "Epoch 403/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1999 - accuracy: 0.9161 - val_loss: 2.5905 - val_accuracy: 0.5110\n",
      "Epoch 404/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1962 - accuracy: 0.9175 - val_loss: 2.5775 - val_accuracy: 0.5110\n",
      "Epoch 405/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1929 - accuracy: 0.9190 - val_loss: 2.6370 - val_accuracy: 0.5154\n",
      "Epoch 406/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1939 - accuracy: 0.9161 - val_loss: 2.6116 - val_accuracy: 0.5242\n",
      "Epoch 407/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1883 - accuracy: 0.9215 - val_loss: 2.6255 - val_accuracy: 0.5242\n",
      "Epoch 408/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1881 - accuracy: 0.9244 - val_loss: 2.6735 - val_accuracy: 0.5110\n",
      "Epoch 409/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1907 - accuracy: 0.9175 - val_loss: 2.6902 - val_accuracy: 0.5198\n",
      "Epoch 410/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2002 - accuracy: 0.9151 - val_loss: 2.6880 - val_accuracy: 0.5286\n",
      "Epoch 411/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2096 - accuracy: 0.9097 - val_loss: 2.7002 - val_accuracy: 0.5022\n",
      "Epoch 412/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2175 - accuracy: 0.8999 - val_loss: 2.7215 - val_accuracy: 0.5242\n",
      "Epoch 413/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2557 - accuracy: 0.8871 - val_loss: 2.5640 - val_accuracy: 0.5374\n",
      "Epoch 414/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2406 - accuracy: 0.8954 - val_loss: 2.4004 - val_accuracy: 0.5066\n",
      "Epoch 415/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2130 - accuracy: 0.9062 - val_loss: 2.5159 - val_accuracy: 0.5463\n",
      "Epoch 416/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1881 - accuracy: 0.9190 - val_loss: 2.6802 - val_accuracy: 0.5330\n",
      "Epoch 417/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1921 - accuracy: 0.9190 - val_loss: 2.7292 - val_accuracy: 0.5507\n",
      "Epoch 418/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1929 - accuracy: 0.9195 - val_loss: 2.7655 - val_accuracy: 0.5330\n",
      "Epoch 419/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1927 - accuracy: 0.9200 - val_loss: 2.7708 - val_accuracy: 0.5330\n",
      "Epoch 420/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1913 - accuracy: 0.9185 - val_loss: 2.6474 - val_accuracy: 0.5595\n",
      "Epoch 421/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1939 - accuracy: 0.9131 - val_loss: 2.7221 - val_accuracy: 0.5463\n",
      "Epoch 422/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2445 - accuracy: 0.8940 - val_loss: 2.7921 - val_accuracy: 0.5242\n",
      "Epoch 423/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2018 - accuracy: 0.9092 - val_loss: 2.9053 - val_accuracy: 0.5286\n",
      "Epoch 424/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.2420 - accuracy: 0.8895 - val_loss: 2.8670 - val_accuracy: 0.5507\n",
      "Epoch 425/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2334 - accuracy: 0.8925 - val_loss: 2.7687 - val_accuracy: 0.5551\n",
      "Epoch 426/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2857 - accuracy: 0.8797 - val_loss: 2.6590 - val_accuracy: 0.5242\n",
      "Epoch 427/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2830 - accuracy: 0.8846 - val_loss: 2.7800 - val_accuracy: 0.5022\n",
      "Epoch 428/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2601 - accuracy: 0.8812 - val_loss: 2.6959 - val_accuracy: 0.5463\n",
      "Epoch 429/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1801 - accuracy: 0.9273 - val_loss: 2.6977 - val_accuracy: 0.5374\n",
      "Epoch 430/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1998 - accuracy: 0.9043 - val_loss: 2.8888 - val_accuracy: 0.5242\n",
      "Epoch 431/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3383 - accuracy: 0.8621 - val_loss: 2.8571 - val_accuracy: 0.5374\n",
      "Epoch 432/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.3233 - accuracy: 0.8576 - val_loss: 2.9822 - val_accuracy: 0.5022\n",
      "Epoch 433/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3147 - accuracy: 0.8611 - val_loss: 2.4357 - val_accuracy: 0.5286\n",
      "Epoch 434/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2633 - accuracy: 0.8792 - val_loss: 2.6772 - val_accuracy: 0.5463\n",
      "Epoch 435/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2557 - accuracy: 0.8915 - val_loss: 2.9661 - val_accuracy: 0.5286\n",
      "Epoch 436/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2311 - accuracy: 0.8945 - val_loss: 2.5747 - val_accuracy: 0.5242\n",
      "Epoch 437/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2243 - accuracy: 0.9008 - val_loss: 2.5787 - val_accuracy: 0.5330\n",
      "Epoch 438/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2193 - accuracy: 0.9048 - val_loss: 2.3664 - val_accuracy: 0.5242\n",
      "Epoch 439/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1841 - accuracy: 0.9224 - val_loss: 2.4408 - val_accuracy: 0.5374\n",
      "Epoch 440/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1759 - accuracy: 0.9229 - val_loss: 2.5549 - val_accuracy: 0.5419\n",
      "Epoch 441/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1705 - accuracy: 0.9288 - val_loss: 2.6084 - val_accuracy: 0.5374\n",
      "Epoch 442/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1688 - accuracy: 0.9303 - val_loss: 2.8637 - val_accuracy: 0.5330\n",
      "Epoch 443/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1863 - accuracy: 0.9190 - val_loss: 2.7094 - val_accuracy: 0.5286\n",
      "Epoch 444/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2083 - accuracy: 0.9082 - val_loss: 2.5982 - val_accuracy: 0.5595\n",
      "Epoch 445/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1720 - accuracy: 0.9249 - val_loss: 2.7885 - val_accuracy: 0.5330\n",
      "Epoch 446/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1498 - accuracy: 0.9362 - val_loss: 2.7509 - val_accuracy: 0.5639\n",
      "Epoch 447/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1463 - accuracy: 0.9381 - val_loss: 2.7824 - val_accuracy: 0.5639\n",
      "Epoch 448/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1429 - accuracy: 0.9391 - val_loss: 2.9008 - val_accuracy: 0.5727\n",
      "Epoch 449/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1428 - accuracy: 0.9377 - val_loss: 2.9172 - val_accuracy: 0.5639\n",
      "Epoch 450/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1403 - accuracy: 0.9377 - val_loss: 2.9336 - val_accuracy: 0.5639\n",
      "Epoch 451/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1378 - accuracy: 0.9401 - val_loss: 2.9411 - val_accuracy: 0.5727\n",
      "Epoch 452/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1366 - accuracy: 0.9396 - val_loss: 2.9561 - val_accuracy: 0.5639\n",
      "Epoch 453/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1336 - accuracy: 0.9431 - val_loss: 2.9510 - val_accuracy: 0.5639\n",
      "Epoch 454/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1311 - accuracy: 0.9431 - val_loss: 3.0221 - val_accuracy: 0.5595\n",
      "Epoch 455/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1295 - accuracy: 0.9440 - val_loss: 3.0234 - val_accuracy: 0.5595\n",
      "Epoch 456/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1276 - accuracy: 0.9475 - val_loss: 3.0518 - val_accuracy: 0.5595\n",
      "Epoch 457/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1262 - accuracy: 0.9489 - val_loss: 3.0375 - val_accuracy: 0.5507\n",
      "Epoch 458/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1253 - accuracy: 0.9499 - val_loss: 3.0661 - val_accuracy: 0.5463\n",
      "Epoch 459/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1233 - accuracy: 0.9494 - val_loss: 3.0229 - val_accuracy: 0.5330\n",
      "Epoch 460/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1227 - accuracy: 0.9475 - val_loss: 2.9797 - val_accuracy: 0.5507\n",
      "Epoch 461/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1191 - accuracy: 0.9529 - val_loss: 2.9834 - val_accuracy: 0.5551\n",
      "Epoch 462/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1198 - accuracy: 0.9519 - val_loss: 2.9668 - val_accuracy: 0.5419\n",
      "Epoch 463/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1213 - accuracy: 0.9494 - val_loss: 2.9892 - val_accuracy: 0.5419\n",
      "Epoch 464/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1182 - accuracy: 0.9548 - val_loss: 2.9791 - val_accuracy: 0.5507\n",
      "Epoch 465/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1179 - accuracy: 0.9543 - val_loss: 2.9930 - val_accuracy: 0.5374\n",
      "Epoch 466/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1169 - accuracy: 0.9548 - val_loss: 3.0122 - val_accuracy: 0.5374\n",
      "Epoch 467/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1171 - accuracy: 0.9543 - val_loss: 2.9483 - val_accuracy: 0.5286\n",
      "Epoch 468/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1148 - accuracy: 0.9558 - val_loss: 3.0823 - val_accuracy: 0.5242\n",
      "Epoch 469/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1178 - accuracy: 0.9539 - val_loss: 3.0096 - val_accuracy: 0.5198\n",
      "Epoch 470/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1258 - accuracy: 0.9524 - val_loss: 3.1364 - val_accuracy: 0.5286\n",
      "Epoch 471/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1237 - accuracy: 0.9485 - val_loss: 3.0831 - val_accuracy: 0.5419\n",
      "Epoch 472/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1339 - accuracy: 0.9396 - val_loss: 2.9225 - val_accuracy: 0.5154\n",
      "Epoch 473/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1492 - accuracy: 0.9411 - val_loss: 3.2534 - val_accuracy: 0.5419\n",
      "Epoch 474/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1675 - accuracy: 0.9283 - val_loss: 2.9163 - val_accuracy: 0.5639\n",
      "Epoch 475/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1857 - accuracy: 0.9249 - val_loss: 2.8143 - val_accuracy: 0.5419\n",
      "Epoch 476/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1945 - accuracy: 0.9244 - val_loss: 2.8229 - val_accuracy: 0.5022\n",
      "Epoch 477/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2401 - accuracy: 0.9057 - val_loss: 2.8086 - val_accuracy: 0.5463\n",
      "Epoch 478/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2355 - accuracy: 0.9102 - val_loss: 2.9427 - val_accuracy: 0.5286\n",
      "Epoch 479/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1470 - accuracy: 0.9367 - val_loss: 2.9946 - val_accuracy: 0.5330\n",
      "Epoch 480/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1317 - accuracy: 0.9440 - val_loss: 3.0250 - val_accuracy: 0.5374\n",
      "Epoch 481/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1496 - accuracy: 0.9372 - val_loss: 2.8629 - val_accuracy: 0.5507\n",
      "Epoch 482/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1277 - accuracy: 0.9470 - val_loss: 2.8039 - val_accuracy: 0.5463\n",
      "Epoch 483/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1100 - accuracy: 0.9588 - val_loss: 2.9622 - val_accuracy: 0.5463\n",
      "Epoch 484/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1129 - accuracy: 0.9568 - val_loss: 2.7517 - val_accuracy: 0.5463\n",
      "Epoch 485/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1113 - accuracy: 0.9529 - val_loss: 2.8383 - val_accuracy: 0.5419\n",
      "Epoch 486/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1082 - accuracy: 0.9558 - val_loss: 2.9116 - val_accuracy: 0.5595\n",
      "Epoch 487/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1037 - accuracy: 0.9578 - val_loss: 2.8541 - val_accuracy: 0.5374\n",
      "Epoch 488/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1045 - accuracy: 0.9617 - val_loss: 2.8536 - val_accuracy: 0.5595\n",
      "Epoch 489/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1023 - accuracy: 0.9597 - val_loss: 3.0818 - val_accuracy: 0.5639\n",
      "Epoch 490/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1020 - accuracy: 0.9583 - val_loss: 3.0782 - val_accuracy: 0.5463\n",
      "Epoch 491/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0991 - accuracy: 0.9632 - val_loss: 3.0314 - val_accuracy: 0.5551\n",
      "Epoch 492/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1150 - accuracy: 0.9543 - val_loss: 3.0207 - val_accuracy: 0.5242\n",
      "Epoch 493/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1041 - accuracy: 0.9642 - val_loss: 3.0309 - val_accuracy: 0.5374\n",
      "Epoch 494/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1102 - accuracy: 0.9558 - val_loss: 2.9653 - val_accuracy: 0.5330\n",
      "Epoch 495/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1220 - accuracy: 0.9489 - val_loss: 3.1344 - val_accuracy: 0.5419\n",
      "Epoch 496/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1319 - accuracy: 0.9480 - val_loss: 3.0210 - val_accuracy: 0.5419\n",
      "Epoch 497/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1136 - accuracy: 0.9543 - val_loss: 3.0364 - val_accuracy: 0.5683\n",
      "Epoch 498/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1157 - accuracy: 0.9514 - val_loss: 3.0061 - val_accuracy: 0.5330\n",
      "Epoch 499/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1222 - accuracy: 0.9494 - val_loss: 3.2304 - val_accuracy: 0.5374\n",
      "Epoch 500/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1098 - accuracy: 0.9632 - val_loss: 3.1188 - val_accuracy: 0.5374\n",
      "Epoch 501/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1122 - accuracy: 0.9588 - val_loss: 2.9904 - val_accuracy: 0.5727\n",
      "Epoch 502/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1010 - accuracy: 0.9617 - val_loss: 2.9228 - val_accuracy: 0.5507\n",
      "Epoch 503/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0998 - accuracy: 0.9627 - val_loss: 2.9697 - val_accuracy: 0.5507\n",
      "Epoch 504/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1209 - accuracy: 0.9548 - val_loss: 2.9774 - val_accuracy: 0.5595\n",
      "Epoch 505/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1128 - accuracy: 0.9558 - val_loss: 3.2484 - val_accuracy: 0.5639\n",
      "Epoch 506/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1290 - accuracy: 0.9475 - val_loss: 3.0346 - val_accuracy: 0.5419\n",
      "Epoch 507/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1174 - accuracy: 0.9553 - val_loss: 3.2394 - val_accuracy: 0.5286\n",
      "Epoch 508/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1174 - accuracy: 0.9514 - val_loss: 3.2263 - val_accuracy: 0.5286\n",
      "Epoch 509/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1153 - accuracy: 0.9519 - val_loss: 3.1993 - val_accuracy: 0.5286\n",
      "Epoch 510/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1232 - accuracy: 0.9509 - val_loss: 3.4330 - val_accuracy: 0.5463\n",
      "Epoch 511/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2132 - accuracy: 0.9234 - val_loss: 2.9055 - val_accuracy: 0.5463\n",
      "Epoch 512/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4450 - accuracy: 0.8665 - val_loss: 2.7824 - val_accuracy: 0.5242\n",
      "Epoch 513/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.4827 - accuracy: 0.8238 - val_loss: 2.5423 - val_accuracy: 0.5022\n",
      "Epoch 514/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3595 - accuracy: 0.8679 - val_loss: 2.7885 - val_accuracy: 0.5110\n",
      "Epoch 515/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2427 - accuracy: 0.8979 - val_loss: 2.6940 - val_accuracy: 0.5242\n",
      "Epoch 516/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2023 - accuracy: 0.9200 - val_loss: 2.8853 - val_accuracy: 0.5419\n",
      "Epoch 517/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2495 - accuracy: 0.9043 - val_loss: 2.8565 - val_accuracy: 0.5242\n",
      "Epoch 518/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1866 - accuracy: 0.9313 - val_loss: 2.7448 - val_accuracy: 0.5374\n",
      "Epoch 519/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1638 - accuracy: 0.9342 - val_loss: 2.8864 - val_accuracy: 0.5066\n",
      "Epoch 520/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1527 - accuracy: 0.9381 - val_loss: 2.5524 - val_accuracy: 0.5551\n",
      "Epoch 521/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1906 - accuracy: 0.9288 - val_loss: 2.8970 - val_accuracy: 0.5022\n",
      "Epoch 522/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1575 - accuracy: 0.9367 - val_loss: 2.6734 - val_accuracy: 0.5595\n",
      "Epoch 523/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1291 - accuracy: 0.9450 - val_loss: 2.9525 - val_accuracy: 0.5198\n",
      "Epoch 524/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1070 - accuracy: 0.9573 - val_loss: 2.8086 - val_accuracy: 0.5374\n",
      "Epoch 525/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1075 - accuracy: 0.9612 - val_loss: 2.9140 - val_accuracy: 0.5330\n",
      "Epoch 526/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0965 - accuracy: 0.9661 - val_loss: 2.8628 - val_accuracy: 0.5595\n",
      "Epoch 527/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0939 - accuracy: 0.9696 - val_loss: 2.8975 - val_accuracy: 0.5463\n",
      "Epoch 528/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0942 - accuracy: 0.9701 - val_loss: 2.8888 - val_accuracy: 0.5374\n",
      "Epoch 529/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0932 - accuracy: 0.9705 - val_loss: 2.9523 - val_accuracy: 0.5374\n",
      "Epoch 530/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0900 - accuracy: 0.9705 - val_loss: 3.0213 - val_accuracy: 0.5154\n",
      "Epoch 531/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0888 - accuracy: 0.9735 - val_loss: 3.1219 - val_accuracy: 0.5198\n",
      "Epoch 532/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0870 - accuracy: 0.9740 - val_loss: 3.1051 - val_accuracy: 0.5198\n",
      "Epoch 533/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0859 - accuracy: 0.9735 - val_loss: 3.1908 - val_accuracy: 0.5066\n",
      "Epoch 534/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0824 - accuracy: 0.9745 - val_loss: 3.1445 - val_accuracy: 0.5154\n",
      "Epoch 535/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0810 - accuracy: 0.9755 - val_loss: 3.1644 - val_accuracy: 0.5198\n",
      "Epoch 536/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0801 - accuracy: 0.9740 - val_loss: 3.1485 - val_accuracy: 0.5066\n",
      "Epoch 537/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0791 - accuracy: 0.9740 - val_loss: 3.2018 - val_accuracy: 0.5022\n",
      "Epoch 538/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0770 - accuracy: 0.9750 - val_loss: 3.2356 - val_accuracy: 0.4846\n",
      "Epoch 539/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0776 - accuracy: 0.9735 - val_loss: 3.2743 - val_accuracy: 0.4934\n",
      "Epoch 540/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0764 - accuracy: 0.9715 - val_loss: 3.3000 - val_accuracy: 0.4978\n",
      "Epoch 541/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0744 - accuracy: 0.9755 - val_loss: 3.3161 - val_accuracy: 0.5022\n",
      "Epoch 542/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0717 - accuracy: 0.9759 - val_loss: 3.3043 - val_accuracy: 0.5242\n",
      "Epoch 543/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 3.2978 - val_accuracy: 0.5198\n",
      "Epoch 544/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0685 - accuracy: 0.9779 - val_loss: 3.2596 - val_accuracy: 0.5286\n",
      "Epoch 545/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0677 - accuracy: 0.9779 - val_loss: 3.2556 - val_accuracy: 0.5286\n",
      "Epoch 546/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0672 - accuracy: 0.9774 - val_loss: 3.3028 - val_accuracy: 0.5242\n",
      "Epoch 547/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0647 - accuracy: 0.9789 - val_loss: 3.3078 - val_accuracy: 0.5330\n",
      "Epoch 548/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0648 - accuracy: 0.9799 - val_loss: 3.3180 - val_accuracy: 0.5374\n",
      "Epoch 549/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0660 - accuracy: 0.9794 - val_loss: 3.3854 - val_accuracy: 0.5242\n",
      "Epoch 550/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0649 - accuracy: 0.9784 - val_loss: 3.3719 - val_accuracy: 0.5330\n",
      "Epoch 551/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0682 - accuracy: 0.9755 - val_loss: 3.3895 - val_accuracy: 0.5330\n",
      "Epoch 552/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0699 - accuracy: 0.9745 - val_loss: 3.3989 - val_accuracy: 0.5330\n",
      "Epoch 553/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0737 - accuracy: 0.9730 - val_loss: 3.3626 - val_accuracy: 0.5242\n",
      "Epoch 554/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0740 - accuracy: 0.9740 - val_loss: 3.4525 - val_accuracy: 0.5198\n",
      "Epoch 555/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0652 - accuracy: 0.9774 - val_loss: 3.3862 - val_accuracy: 0.5286\n",
      "Epoch 556/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0676 - accuracy: 0.9769 - val_loss: 3.5239 - val_accuracy: 0.5330\n",
      "Epoch 557/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0607 - accuracy: 0.9789 - val_loss: 3.4334 - val_accuracy: 0.5154\n",
      "Epoch 558/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0597 - accuracy: 0.9799 - val_loss: 3.4243 - val_accuracy: 0.5374\n",
      "Epoch 559/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0587 - accuracy: 0.9809 - val_loss: 3.4542 - val_accuracy: 0.5330\n",
      "Epoch 560/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0585 - accuracy: 0.9813 - val_loss: 3.3509 - val_accuracy: 0.5374\n",
      "Epoch 561/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0570 - accuracy: 0.9823 - val_loss: 3.3924 - val_accuracy: 0.5551\n",
      "Epoch 562/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0553 - accuracy: 0.9828 - val_loss: 3.4105 - val_accuracy: 0.5507\n",
      "Epoch 563/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0555 - accuracy: 0.9823 - val_loss: 3.4048 - val_accuracy: 0.5463\n",
      "Epoch 564/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 3.4818 - val_accuracy: 0.5374\n",
      "Epoch 565/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0525 - accuracy: 0.9828 - val_loss: 3.5044 - val_accuracy: 0.5419\n",
      "Epoch 566/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 3.5425 - val_accuracy: 0.5330\n",
      "Epoch 567/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0512 - accuracy: 0.9838 - val_loss: 3.5393 - val_accuracy: 0.5419\n",
      "Epoch 568/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0529 - accuracy: 0.9818 - val_loss: 3.5725 - val_accuracy: 0.5419\n",
      "Epoch 569/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0519 - accuracy: 0.9818 - val_loss: 3.5743 - val_accuracy: 0.5330\n",
      "Epoch 570/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 3.5994 - val_accuracy: 0.5463\n",
      "Epoch 571/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0502 - accuracy: 0.9828 - val_loss: 3.6326 - val_accuracy: 0.5330\n",
      "Epoch 572/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0488 - accuracy: 0.9833 - val_loss: 3.6639 - val_accuracy: 0.5286\n",
      "Epoch 573/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0479 - accuracy: 0.9828 - val_loss: 3.6794 - val_accuracy: 0.5242\n",
      "Epoch 574/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 3.6675 - val_accuracy: 0.5330\n",
      "Epoch 575/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0475 - accuracy: 0.9838 - val_loss: 3.7143 - val_accuracy: 0.5242\n",
      "Epoch 576/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0524 - accuracy: 0.9804 - val_loss: 3.7048 - val_accuracy: 0.5595\n",
      "Epoch 577/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0530 - accuracy: 0.9804 - val_loss: 3.6607 - val_accuracy: 0.5507\n",
      "Epoch 578/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0531 - accuracy: 0.9794 - val_loss: 3.6748 - val_accuracy: 0.5507\n",
      "Epoch 579/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 3.6104 - val_accuracy: 0.5419\n",
      "Epoch 580/5000\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0534 - accuracy: 0.9809 - val_loss: 3.5962 - val_accuracy: 0.5242\n",
      "Epoch 581/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0504 - accuracy: 0.9833 - val_loss: 3.5796 - val_accuracy: 0.5286\n",
      "Epoch 582/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 3.5671 - val_accuracy: 0.5507\n",
      "Epoch 583/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0482 - accuracy: 0.9882 - val_loss: 3.6176 - val_accuracy: 0.5198\n",
      "Epoch 584/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0440 - accuracy: 0.9887 - val_loss: 3.7826 - val_accuracy: 0.5066\n",
      "Epoch 585/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0405 - accuracy: 0.9892 - val_loss: 3.8089 - val_accuracy: 0.5330\n",
      "Epoch 586/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0486 - accuracy: 0.9843 - val_loss: 3.7197 - val_accuracy: 0.5198\n",
      "Epoch 587/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 3.7171 - val_accuracy: 0.5330\n",
      "Epoch 588/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0431 - accuracy: 0.9877 - val_loss: 3.7391 - val_accuracy: 0.5242\n",
      "Epoch 589/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0393 - accuracy: 0.9892 - val_loss: 3.7833 - val_accuracy: 0.5463\n",
      "Epoch 590/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0529 - accuracy: 0.9838 - val_loss: 3.7374 - val_accuracy: 0.5507\n",
      "Epoch 591/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 3.7700 - val_accuracy: 0.5463\n",
      "Epoch 592/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0562 - accuracy: 0.9818 - val_loss: 3.7574 - val_accuracy: 0.5463\n",
      "Epoch 593/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0421 - accuracy: 0.9877 - val_loss: 3.7869 - val_accuracy: 0.5551\n",
      "Epoch 594/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0390 - accuracy: 0.9892 - val_loss: 3.7873 - val_accuracy: 0.5507\n",
      "Epoch 595/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0370 - accuracy: 0.9907 - val_loss: 3.7757 - val_accuracy: 0.5374\n",
      "Epoch 596/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0385 - accuracy: 0.9892 - val_loss: 3.7639 - val_accuracy: 0.5419\n",
      "Epoch 597/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0375 - accuracy: 0.9897 - val_loss: 3.7690 - val_accuracy: 0.5463\n",
      "Epoch 598/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0386 - accuracy: 0.9902 - val_loss: 3.6905 - val_accuracy: 0.5463\n",
      "Epoch 599/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 3.6454 - val_accuracy: 0.5374\n",
      "Epoch 600/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0379 - accuracy: 0.9897 - val_loss: 3.7264 - val_accuracy: 0.5639\n",
      "Epoch 601/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 3.8124 - val_accuracy: 0.5419\n",
      "Epoch 602/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0371 - accuracy: 0.9897 - val_loss: 3.7685 - val_accuracy: 0.5551\n",
      "Epoch 603/5000\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.0345 - accuracy: 0.9907 - val_loss: 3.8233 - val_accuracy: 0.5463\n",
      "Epoch 604/5000\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.0354 - accuracy: 0.9897 - val_loss: 3.8424 - val_accuracy: 0.5374\n",
      "Epoch 605/5000\n",
      "64/64 [==============================] - 1s 14ms/step - loss: 0.0333 - accuracy: 0.9931 - val_loss: 3.8801 - val_accuracy: 0.5330\n",
      "Epoch 606/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0339 - accuracy: 0.9917 - val_loss: 3.8566 - val_accuracy: 0.5419\n",
      "Epoch 607/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 3.8403 - val_accuracy: 0.5595\n",
      "Epoch 608/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 3.7371 - val_accuracy: 0.5595\n",
      "Epoch 609/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0474 - accuracy: 0.9867 - val_loss: 3.7734 - val_accuracy: 0.5419\n",
      "Epoch 610/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0446 - accuracy: 0.9877 - val_loss: 3.7708 - val_accuracy: 0.5463\n",
      "Epoch 611/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0755 - accuracy: 0.9774 - val_loss: 3.7967 - val_accuracy: 0.5595\n",
      "Epoch 612/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0950 - accuracy: 0.9691 - val_loss: 3.6123 - val_accuracy: 0.5242\n",
      "Epoch 613/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1466 - accuracy: 0.9534 - val_loss: 3.7974 - val_accuracy: 0.5463\n",
      "Epoch 614/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3921 - accuracy: 0.8945 - val_loss: 3.5243 - val_accuracy: 0.5198\n",
      "Epoch 615/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2778 - accuracy: 0.9165 - val_loss: 3.2797 - val_accuracy: 0.5286\n",
      "Epoch 616/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2709 - accuracy: 0.9116 - val_loss: 3.3223 - val_accuracy: 0.5551\n",
      "Epoch 617/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2467 - accuracy: 0.9156 - val_loss: 3.2636 - val_accuracy: 0.5815\n",
      "Epoch 618/5000\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.95 - 1s 12ms/step - loss: 0.1408 - accuracy: 0.9588 - val_loss: 3.2634 - val_accuracy: 0.5374\n",
      "Epoch 619/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1316 - accuracy: 0.9435 - val_loss: 3.3506 - val_accuracy: 0.5066\n",
      "Epoch 620/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0761 - accuracy: 0.9764 - val_loss: 3.3930 - val_accuracy: 0.5198\n",
      "Epoch 621/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0650 - accuracy: 0.9794 - val_loss: 3.3459 - val_accuracy: 0.5463\n",
      "Epoch 622/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0471 - accuracy: 0.9877 - val_loss: 3.3603 - val_accuracy: 0.5551\n",
      "Epoch 623/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0419 - accuracy: 0.9897 - val_loss: 3.4455 - val_accuracy: 0.5595\n",
      "Epoch 624/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0393 - accuracy: 0.9912 - val_loss: 3.5052 - val_accuracy: 0.5595\n",
      "Epoch 625/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0374 - accuracy: 0.9926 - val_loss: 3.5251 - val_accuracy: 0.5419\n",
      "Epoch 626/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0370 - accuracy: 0.9907 - val_loss: 3.5479 - val_accuracy: 0.5551\n",
      "Epoch 627/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0367 - accuracy: 0.9917 - val_loss: 3.6208 - val_accuracy: 0.5374\n",
      "Epoch 628/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 3.5850 - val_accuracy: 0.5463\n",
      "Epoch 629/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0342 - accuracy: 0.9926 - val_loss: 3.5471 - val_accuracy: 0.5419\n",
      "Epoch 630/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0336 - accuracy: 0.9931 - val_loss: 3.5899 - val_accuracy: 0.5551\n",
      "Epoch 631/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0479 - accuracy: 0.9887 - val_loss: 3.6514 - val_accuracy: 0.5286\n",
      "Epoch 632/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0849 - accuracy: 0.9750 - val_loss: 3.2964 - val_accuracy: 0.5727\n",
      "Epoch 633/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0845 - accuracy: 0.9764 - val_loss: 3.5290 - val_accuracy: 0.5242\n",
      "Epoch 634/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0580 - accuracy: 0.9867 - val_loss: 3.4811 - val_accuracy: 0.5683\n",
      "Epoch 635/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0801 - accuracy: 0.9804 - val_loss: 3.8484 - val_accuracy: 0.5419\n",
      "Epoch 636/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0798 - accuracy: 0.9705 - val_loss: 3.5844 - val_accuracy: 0.5683\n",
      "Epoch 637/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0487 - accuracy: 0.9848 - val_loss: 3.8088 - val_accuracy: 0.5198\n",
      "Epoch 638/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0433 - accuracy: 0.9882 - val_loss: 3.6128 - val_accuracy: 0.5286\n",
      "Epoch 639/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0323 - accuracy: 0.9926 - val_loss: 3.6795 - val_accuracy: 0.5419\n",
      "Epoch 640/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0312 - accuracy: 0.9946 - val_loss: 3.6983 - val_accuracy: 0.5463\n",
      "Epoch 641/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0306 - accuracy: 0.9931 - val_loss: 3.7158 - val_accuracy: 0.5374\n",
      "Epoch 642/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0316 - accuracy: 0.9926 - val_loss: 3.7490 - val_accuracy: 0.5154\n",
      "Epoch 643/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0318 - accuracy: 0.9921 - val_loss: 3.7508 - val_accuracy: 0.5110\n",
      "Epoch 644/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0323 - accuracy: 0.9926 - val_loss: 3.7719 - val_accuracy: 0.5198\n",
      "Epoch 645/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0320 - accuracy: 0.9921 - val_loss: 3.7763 - val_accuracy: 0.5242\n",
      "Epoch 646/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0311 - accuracy: 0.9931 - val_loss: 3.7616 - val_accuracy: 0.5066\n",
      "Epoch 647/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0305 - accuracy: 0.9951 - val_loss: 3.7839 - val_accuracy: 0.5242\n",
      "Epoch 648/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9941 - val_loss: 3.7798 - val_accuracy: 0.5330\n",
      "Epoch 649/5000\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0308 - accuracy: 0.9946 - val_loss: 3.7881 - val_accuracy: 0.5286\n",
      "Epoch 650/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0310 - accuracy: 0.9936 - val_loss: 3.7825 - val_accuracy: 0.5330\n",
      "Epoch 651/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9936 - val_loss: 3.7918 - val_accuracy: 0.5286\n",
      "Epoch 652/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9931 - val_loss: 3.7855 - val_accuracy: 0.5330\n",
      "Epoch 653/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0317 - accuracy: 0.9936 - val_loss: 3.7712 - val_accuracy: 0.5286\n",
      "Epoch 654/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0306 - accuracy: 0.9951 - val_loss: 3.7431 - val_accuracy: 0.5198\n",
      "Epoch 655/5000\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0328 - accuracy: 0.9921 - val_loss: 3.7946 - val_accuracy: 0.5286\n",
      "Epoch 00655: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cb77a49408>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=5000, batch_size=32, validation_split=0.1,validation_freq=1, shuffle=False,use_multiprocessing=True, callbacks=[best_model,earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52523aa",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb20731d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyAUCY0FGwsM"
   },
   "outputs": [],
   "source": [
    "prediction_model = load_model(path,compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebf3f215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shara\\AppData\\Local\\Temp/ipykernel_10332/1073983075.py:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_pred = prediction_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919f063",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2646702",
   "metadata": {},
   "source": [
    "Metrics used in the paper: Accuracy, F1 score, and Area under curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43a4e4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5114638447971781"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=accuracy_score(y_test,y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84fbda78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553772070626004"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1=f1_score(y_test,y_pred,average='binary')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23dfa096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5067128817128816"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc=roc_auc_score(y_test,y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "474be8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    decrease       0.46      0.45      0.46       259\n",
      "    increase       0.55      0.56      0.56       308\n",
      "\n",
      "    accuracy                           0.51       567\n",
      "   macro avg       0.51      0.51      0.51       567\n",
      "weighted avg       0.51      0.51      0.51       567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred,labels=[0,1], target_names=['decrease','increase']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20a7a6",
   "metadata": {},
   "source": [
    "Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33273e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad42122f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[117 142]\n",
      " [135 173]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Confusion Matrix'}, xlabel='Predicted label', ylabel='True label'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import scikitplot as skplt\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "skplt.metrics.plot_confusion_matrix(y_test, y_pred,figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd66b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
